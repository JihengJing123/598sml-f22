{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965e060d-c184-42a5-9891-82df8683d699",
   "metadata": {},
   "source": [
    "# `torch.autograd`: Computing derivatives\n",
    "\n",
    "PyTorch constructs the computation graph as you do operations (dynamic graphs) unlike TensorFlow (static graphs)\n",
    "\n",
    "Using the computation graph, the chain rule (back propagation) can compute derivatives\n",
    "\n",
    "Derivatives are available in the leaf nodes\n",
    "\n",
    "<img src=\"http://media5.datahacker.rs/2021/01/54-1-1536x735.jpg\" width=60%>\n",
    "(Figure from http://datahacker.rs/004-computational-graph-and-autograd-with-pytorch/)\n",
    "\n",
    "Links:\n",
    "- https://datahacker.rs/004-computational-graph-and-autograd-with-pytorch/\n",
    "- http://colah.github.io/posts/2015-08-Backprop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e10cf-4871-4502-9852-a997dbbb268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f2d61-a7f9-4d10-8684-c9758d32bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5603bca-22ec-40d3-8b21-6770c1c6b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefc866-92c7-4b33-b3df-1dc3d69a1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x * w**2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f0375-3081-4deb-ab64-1357362201d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()\n",
    "print(f'x.grad = {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301d526-1483-43cd-bbfe-27345b72778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'w.grad = {w.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257a9b3-9aa2-43f1-b442-568ac0f64a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9415e2-8cfb-4f50-9b03-cd081e637f55",
   "metadata": {},
   "source": [
    "Now $\\frac{\\partial z}{\\partial w} = 2 x w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf5611-c1d4-4672-8318-a9a843f20533",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * x * w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272a33e-5ea0-405a-9e11-16f4abf969ec",
   "metadata": {},
   "source": [
    "### Computing derivatives ... or not\n",
    "https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f4170-9093-49f3-9e5f-91119550281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x*x\n",
    "print(f'y.requires_grad = {y.requires_grad}')\n",
    "z = x*y\n",
    "z.backward()\n",
    "print(f'dz/dx = {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051ff2d-089f-4383-b0f0-be25754a6100",
   "metadata": {},
   "source": [
    "We can \"detach\" a variable from the computation graph...\n",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.detach.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd521c8-784b-4db7-86ef-1fd482f212f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x*x\n",
    "y = y.detach() # can't say y.requires_grad = False\n",
    "print(f'y.requires_grad = {y.requires_grad}')\n",
    "z = x*y\n",
    "z.backward()\n",
    "print(f'dz/dx = {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd8279-13bc-4b80-9253-4972a0f4eb61",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54650b3c-e9d4-40fc-b45f-c8a76b84bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x*x\n",
    "print(f'y.requires_grad = {y.requires_grad}')\n",
    "z = x*y\n",
    "z.backward()\n",
    "print(f'dz/dx = {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c7312-41db-44c0-9d53-9025f3517950",
   "metadata": {},
   "source": [
    "### Computation graphs are not trees\n",
    "\n",
    "Re-using a parameter in multiple places makes the graph not be a tree. It's a DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ac1d8-7a8e-4201-a5a7-2323fc9052a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = 3*x\n",
    "z = x**2\n",
    "w = y + z + x\n",
    "w.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4fa5c-8009-486c-a681-602d5c72774f",
   "metadata": {},
   "source": [
    "$\\frac{\\partial w}{\\partial x} = \\frac{\\partial}{\\partial x}(3x + x^2 + x) = 3 + 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f016d-723d-4aa1-9697-f8d374272ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 + 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f7554-6d1d-4d73-953b-66de95626983",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2\n",
    "z1 = 3*y\n",
    "z2 = 4*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525f477-2247-420a-b112-f25342434071",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1.backward() # (retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8d0ca-2899-45df-977a-db3727a15da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2.backward()\n",
    "x.grad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d9823-e99c-4291-9659-ba9740856172",
   "metadata": {},
   "source": [
    "### Accumulating effect\n",
    "\n",
    "`.grad` stores the gradient.  Take a look:\n",
    "https://pytorch.org/docs/stable/generated/torch.autograd.grad.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fff7d-100f-493f-80f1-de7056f2840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2\n",
    "z = 3*y\n",
    "print(x.grad)\n",
    "\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "\n",
    "#x.grad.zero_()\n",
    "y = x**2\n",
    "z = 3*y\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a9efa-ffc7-4bd3-853a-f22a98ca1c77",
   "metadata": {},
   "source": [
    "#### Derivatives of scalars with respect to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6742c7-29b9-4543-b233-808145b51be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = (x**2).sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afcf67-5eb7-4e5d-b884-b85dc513f745",
   "metadata": {},
   "source": [
    "#### Don't do in-place modifications to tensors\n",
    "\n",
    "But it's fine to do `x = 4 * x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6f66f-7247-49ea-b762-0ef1040e10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1810d6-4c9b-4478-9c62-852d3d90d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1] = x[2] + 1\n",
    "#x = 4*x\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb51288-27d0-4f08-ad4b-29b2443f2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x**2).sum()\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe32697-1d18-4e21-b833-7e8d0ecabeff",
   "metadata": {},
   "source": [
    "#### Results can be slightly different from what you expect...\n",
    "\n",
    "Since we're building the graph as computations are being done, functions like `max()` become differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a508de-f8ee-4f1c-a858-052e67e37355",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 4.0, 3.0, 0.5], requires_grad=True)\n",
    "max_x = torch.max(x)\n",
    "max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c45262-a15f-4b19-8ffa-336757a6262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x.backward()\n",
    "x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
